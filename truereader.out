Mon Mar 27 09:13:27 2023       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 470.161.03   Driver Version: 470.161.03   CUDA Version: 11.4     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  NVIDIA A100-SXM...  On   | 00000000:84:00.0 Off |                    0 |
| N/A   28C    P0    62W / 400W |      0MiB / 81251MiB |      0%      Default |
|                               |                      |             Disabled |
+-------------------------------+----------------------+----------------------+
|   1  NVIDIA A100-SXM...  On   | 00000000:8A:00.0 Off |                    0 |
| N/A   26C    P0    62W / 400W |      0MiB / 81251MiB |      0%      Default |
|                               |                      |             Disabled |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+
/home/jaded79/texlive/bin/x86_64-linux/pdflatex
/bin/pdftoppm
has whiched

    \documentclass{article}
    \begin{document}
    Hello, world!
    \end{document}
    
now trying with tempfiles

    \documentclass{article}
    \begin{document}
    Hello, world!
    \end{document}
    
now trying with tempfiles
This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) (preloaded format=pdflatex)
 restricted \write18 enabled.
This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) (preloaded format=pdflatex)
 restricted \write18 enabled.
entering extended mode
(/tmp/tmpsuuur0ka/temp.tex
LaTeX2e <2022-11-01> patch level 1
L3 programming layer <2023-02-22>entering extended mode
(/tmp/tmpne70ve2y/temp.tex
LaTeX2e <2022-11-01> patch level 1
L3 programming layer <2023-02-22>
(/home/jaded79/texlive/texmf-dist/tex/latex/base/article.cls
(/home/jaded79/texlive/texmf-dist/tex/latex/base/article.cls
Document Class: article 2022/07/02 v1.4n Standard LaTeX document class
(/home/jaded79/texlive/texmf-dist/tex/latex/base/size10.clo))
Document Class: article 2022/07/02 v1.4n Standard LaTeX document class
(/home/jaded79/texlive/texmf-dist/tex/latex/base/size10.clo))
(/home/jaded79/texlive/texmf-dist/tex/latex/l3backend/l3backend-pdftex.def)
(/home/jaded79/texlive/texmf-dist/tex/latex/l3backend/l3backend-pdftex.def)
No file temp.aux.
[1
No file temp.aux.
[1{/home/jaded79/texlive/texmf-var/fonts/map/pdftex/updmap/pdftex.map}]
(/tmp/tmpsuuur0ka/temp.aux){/home/jaded79/texlive/texmf-var/fonts/map/pdftex/updmap/pdftex.map}]
(/tmp/tmpne70ve2y/temp.aux) )</home/jaded79/texlive/texmf-dist/fonts/type1/publ
ic/amsfonts/cm/cmr10.pfb>
Output written on /tmp/tmpsuuur0ka/temp.pdf (1 page, 12875 bytes).
Transcript written on /tmp/tmpsuuur0ka/temp.log.
 )</home/jaded79/texlive/texmf-dist/fonts/type1/publ
ic/amsfonts/cm/cmr10.pfb>
Output written on /tmp/tmpne70ve2y/temp.pdf (1 page, 12875 bytes).
Transcript written on /tmp/tmpne70ve2y/temp.log.
done with tempfiles
done with tempfiles
/home/jaded79/.conda/envs/mmcoder/lib/python3.11/site-packages/transformers/training_args.py:1356: FutureWarning: using `--fsdp_transformer_layer_cls_to_wrap` is deprecated. Use fsdp_config instead 
  warnings.warn(
/home/jaded79/.conda/envs/mmcoder/lib/python3.11/site-packages/transformers/training_args.py:1356: FutureWarning: using `--fsdp_transformer_layer_cls_to_wrap` is deprecated. Use fsdp_config instead 
  warnings.warn(
/home/jaded79/.conda/envs/mmcoder/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/jaded79/.conda/envs/mmcoder/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
/home/jaded79/.conda/envs/mmcoder/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/jaded79/.conda/envs/mmcoder/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:09<00:09,  9.85s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:09<00:09,  9.87s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:12<00:00,  5.84s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:12<00:00,  6.44s/it]
Some weights of TrueReader were not initialized from the model checkpoint at /home/jaded79/visual-check/llama_weights/ and are newly initialized: ['embed_image.resnet.7.0.downsample.1.bias', 'embed_image.resnet.6.2.bn2.weight', 'embed_image.resnet.4.2.bn1.num_batches_tracked', 'embed_image.resnet.6.1.bn2.weight', 'embed_image.resnet.4.2.bn2.running_var', 'embed_image.resnet.5.3.bn1.running_mean', 'embed_image.resnet.4.0.bn1.running_var', 'embed_image.resnet.7.0.downsample.1.weight', 'embed_image.resnet.4.0.bn3.running_var', 'embed_image.resnet.7.1.conv3.weight', 'embed_image.resnet.4.0.conv1.weight', 'embed_image.resnet.5.1.conv1.weight', 'embed_image.resnet.6.3.bn1.weight', 'embed_image.resnet.7.2.bn3.num_batches_tracked', 'embed_image.resnet.4.2.conv3.weight', 'embed_image.resnet.7.2.bn3.weight', 'embed_image.resnet.7.2.bn3.bias', 'embed_image.resnet.6.3.bn2.bias', 'embed_image.resnet.6.0.bn3.weight', 'embed_image.resnet.4.0.bn1.weight', 'embed_image.resnet.6.5.bn3.running_var', 'embed_image.resnet.4.2.bn3.weight', 'embed_image.resnet.7.0.bn2.weight', 'embed_image.resnet.4.2.bn3.bias', 'embed_image.resnet.4.2.bn1.running_var', 'embed_image.resnet.4.2.bn2.running_mean', 'embed_image.resnet.4.0.bn1.bias', 'embed_image.resnet.4.0.downsample.1.running_var', 'embed_image.resnet.6.0.bn1.weight', 'embed_image.resnet.4.0.bn1.num_batches_tracked', 'embed_image.resnet.7.0.downsample.1.num_batches_tracked', 'embed_image.resnet.6.4.bn3.running_mean', 'embed_image.resnet.6.0.downsample.1.running_mean', 'embed_image.resnet.7.2.bn1.running_var', 'embed_image.resnet.7.1.bn1.num_batches_tracked', 'embed_image.resnet.4.0.bn2.weight', 'embed_image.resnet.5.3.conv3.weight', 'embed_image.resnet.6.5.bn2.weight', 'embed_image.resnet.7.0.bn3.bias', 'embed_image.resnet.6.3.bn2.num_batches_tracked', 'embed_image.resnet.7.2.conv1.weight', 'embed_image.resnet.5.2.bn1.bias', 'embed_image.resnet.6.3.bn3.num_batches_tracked', 'embed_image.resnet.5.3.bn1.bias', 'embed_image.resnet.6.2.conv2.weight', 'embed_image.resnet.5.1.bn1.running_mean', 'embed_image.resnet.7.2.bn2.weight', 'embed_image.resnet.4.2.bn3.num_batches_tracked', 'embed_image.resnet.6.4.conv2.weight', 'embed_image.resnet.6.4.bn1.running_mean', 'embed_image.resnet.4.0.downsample.1.bias', 'embed_image.resnet.6.1.conv1.weight', 'embed_image.resnet.6.0.downsample.1.weight', 'embed_image.resnet.7.1.bn1.running_mean', 'embed_image.resnet.6.1.bn2.bias', 'embed_image.resnet.6.5.bn1.running_mean', 'embed_image.resnet.7.1.bn3.weight', 'embed_image.resnet.5.1.bn3.running_mean', 'embed_image.resnet.7.1.conv2.weight', 'embed_image.resnet.7.2.bn1.num_batches_tracked', 'embed_image.resnet.7.2.conv3.weight', 'embed_image.resnet.4.0.conv2.weight', 'embed_image.resnet.6.0.bn1.running_mean', 'embed_image.resnet.4.1.bn3.running_var', 'embed_image.resnet.7.0.bn1.weight', 'embed_image.resnet.7.1.bn2.bias', 'embed_image.resnet.6.4.bn2.running_var', 'embed_image.resnet.6.2.bn3.running_mean', 'embed_image.resnet.6.0.bn3.num_batches_tracked', 'embed_image.resnet.5.3.bn2.running_var', 'embed_image.resnet.7.1.bn2.running_var', 'embed_image.resnet.5.1.bn2.running_mean', 'embed_image.resnet.6.4.bn3.weight', 'embeddings_project.weight', 'embed_image.resnet.5.0.bn1.bias', 'embed_image.resnet.6.4.bn3.num_batches_tracked', 'embed_image.resnet.6.3.bn1.running_mean', 'embed_image.resnet.7.0.bn2.running_var', 'embed_image.resnet.6.1.bn3.num_batches_tracked', 'embed_image.resnet.7.2.bn2.num_batches_tracked', 'embed_image.resnet.4.1.bn1.running_mean', 'embed_image.resnet.5.0.downsample.1.weight', 'embed_image.resnet.5.2.bn1.running_var', 'embed_image.resnet.7.0.bn3.weight', 'embed_image.resnet.7.2.bn1.running_mean', 'embed_image.resnet.6.5.conv1.weight', 'embed_image.resnet.7.2.conv2.weight', 'embed_image.resnet.5.3.bn2.bias', 'embed_image.resnet.4.1.bn1.running_var', 'embed_image.resnet.7.0.conv3.weight', 'embed_image.resnet.5.2.bn3.bias', 'embed_image.resnet.6.4.bn3.bias', 'embed_image.resnet.7.0.bn2.num_batches_tracked', 'embed_image.resnet.6.2.bn2.running_var', 'embed_image.resnet.5.0.bn2.num_batches_tracked', 'embed_image.resnet.5.1.bn1.running_var', 'embeddings_project.bias', 'embed_image.resnet.6.5.bn1.weight', 'embed_image.resnet.7.1.bn3.num_batches_tracked', 'embed_image.resnet.6.0.bn2.running_var', 'embed_image.resnet.6.2.bn3.bias', 'embed_image.resnet.5.1.bn1.num_batches_tracked', 'embed_image.resnet.5.2.bn2.weight', 'embed_image.resnet.6.5.bn1.num_batches_tracked', 'embed_image.resnet.6.4.bn2.num_batches_tracked', 'embed_image.resnet.5.2.bn3.num_batches_tracked', 'embed_image.resnet.6.2.bn3.running_var', 'embed_image.resnet.5.0.downsample.1.num_batches_tracked', 'embed_image.resnet.5.0.bn1.running_var', 'embed_image.resnet.7.0.conv2.weight', 'embed_image.resnet.6.2.bn1.weight', 'embed_image.resnet.5.0.conv2.weight', 'embed_image.resnet.6.2.bn2.bias', 'embed_image.resnet.6.3.bn2.running_mean', 'embed_image.resnet.5.0.bn3.running_mean', 'embed_image.resnet.6.4.bn1.weight', 'embed_image.resnet.5.1.bn3.weight', 'embed_image.resnet.6.3.bn1.running_var', 'embed_image.resnet.5.2.bn3.weight', 'embed_image.resnet.6.0.bn3.bias', 'embed_image.resnet.6.4.bn2.weight', 'embed_image.resnet.7.2.bn1.weight', 'embed_image.resnet.4.1.bn2.running_var', 'embed_image.resnet.6.1.bn3.running_var', 'embed_image.resnet.7.1.bn2.num_batches_tracked', 'embed_image.resnet.1.bias', 'embed_image.resnet.6.0.downsample.1.bias', 'embed_image.resnet.7.1.bn1.weight', 'embed_image.resnet.6.0.bn2.weight', 'embed_image.resnet.5.2.conv3.weight', 'embed_image.resnet.4.0.bn2.bias', 'embed_image.resnet.7.2.bn3.running_var', 'embed_image.resnet.6.5.bn1.running_var', 'embed_image.resnet.5.0.bn2.running_mean', 'embed_image.resnet.6.0.bn2.running_mean', 'embed_image.resnet.5.0.conv1.weight', 'embed_image.resnet.5.0.bn3.num_batches_tracked', 'embed_image.resnet.6.0.bn2.bias', 'embed_image.resnet.4.1.conv2.weight', 'embed_image.resnet.4.0.downsample.1.running_mean', 'embed_image.resnet.5.3.bn3.weight', 'embed_image.resnet.6.0.bn1.num_batches_tracked', 'embed_image.resnet.5.0.bn2.running_var', 'embed_image.resnet.6.0.conv3.weight', 'embed_image.resnet.5.3.bn1.running_var', 'embed_image.resnet.6.0.downsample.1.running_var', 'embed_image.resnet.6.2.bn2.running_mean', 'embed_image.resnet.6.0.bn2.num_batches_tracked', 'embed_image.resnet.7.2.bn3.running_mean', 'embed_image.resnet.4.2.bn3.running_var', 'embed_image.resnet.5.0.conv3.weight', 'embed_image.resnet.7.1.bn2.running_mean', 'embed_image.resnet.4.1.bn1.num_batches_tracked', 'embed_image.resnet.4.2.bn2.bias', 'embed_image.resnet.6.2.conv1.weight', 'embed_image.resnet.5.3.bn3.running_mean', 'embed_image.resnet.5.0.bn1.running_mean', 'embed_image.resnet.4.2.bn1.running_mean', 'embed_image.resnet.4.1.bn3.running_mean', 'embed_image.resnet.5.2.bn2.bias', 'embed_image.resnet.5.2.bn1.running_mean', 'embed_image.resnet.7.0.bn3.running_var', 'embed_image.resnet.5.0.bn1.num_batches_tracked', 'embed_image.resnet.4.0.downsample.1.weight', 'embed_image.resnet.7.2.bn2.bias', 'embed_image.resnet.4.2.conv1.weight', 'embed_image.resnet.7.1.conv1.weight', 'embed_image.resnet.7.1.bn3.running_mean', 'embed_image.resnet.5.1.conv3.weight', 'embed_image.resnet.6.2.bn1.running_mean', 'embed_image.resnet.5.2.conv2.weight', 'embed_image.resnet.7.1.bn2.weight', 'embed_image.resnet.7.0.bn1.bias', 'embed_image.resnet.6.3.conv1.weight', 'embed_image.resnet.5.3.bn2.running_mean', 'embed_image.resnet.4.1.bn2.bias', 'embed_image.resnet.6.2.conv3.weight', 'embed_image.resnet.6.3.conv3.weight', 'embed_image.resnet.6.1.bn1.num_batches_tracked', 'embed_image.resnet.7.0.bn3.num_batches_tracked', 'embed_image.resnet.5.3.bn1.num_batches_tracked', 'embed_image.resnet.5.1.bn3.num_batches_tracked', 'embed_image.resnet.7.1.bn1.running_var', 'embed_image.resnet.7.0.downsample.1.running_mean', 'embed_image.resnet.5.3.bn1.weight', 'embed_image.resnet.5.2.bn3.running_mean', 'embed_image.resnet.6.1.bn2.running_mean', 'embed_image.resnet.4.2.bn1.weight', 'embed_image.resnet.4.1.bn2.weight', 'embed_image.resnet.5.1.conv2.weight', 'embed_image.resnet.4.1.conv1.weight', 'embed_image.resnet.5.3.bn3.num_batches_tracked', 'embed_image.resnet.4.2.bn3.running_mean', 'embed_image.resnet.6.4.conv3.weight', 'embed_image.resnet.4.2.bn2.num_batches_tracked', 'embed_image.resnet.6.0.bn1.bias', 'embed_image.resnet.6.5.bn2.running_mean', 'embed_image.resnet.6.0.bn1.running_var', 'embed_image.resnet.5.1.bn2.running_var', 'embed_image.resnet.4.0.bn2.running_var', 'embed_image.resnet.7.0.bn1.running_mean', 'embed_image.resnet.6.0.conv2.weight', 'embed_image.resnet.4.1.bn1.bias', 'embed_image.resnet.6.4.bn3.running_var', 'embed_image.resnet.6.0.downsample.1.num_batches_tracked', 'embed_image.resnet.5.0.downsample.1.running_mean', 'embed_image.resnet.6.1.bn2.running_var', 'embed_image.resnet.4.0.bn3.weight', 'embed_image.resnet.6.5.bn2.bias', 'embed_image.resnet.5.1.bn3.bias', 'embed_image.resnet.6.0.bn3.running_var', 'embed_image.resnet.7.0.bn3.running_mean', 'embed_image.resnet.5.0.downsample.1.running_var', 'embed_image.resnet.5.3.conv2.weight', 'embed_image.resnet.7.1.bn3.running_var', 'embed_image.resnet.1.weight', 'embed_image.resnet.4.1.bn2.running_mean', 'embed_image.resnet.1.num_batches_tracked', 'embed_image.resnet.1.running_var', 'embed_image.resnet.6.4.conv1.weight', 'embed_image.resnet.6.2.bn1.running_var', 'embed_image.resnet.5.2.bn3.running_var', 'embed_image.resnet.6.1.bn2.num_batches_tracked', 'embed_image.resnet.6.2.bn1.num_batches_tracked', 'embed_image.resnet.5.1.bn2.bias', 'embed_image.resnet.5.3.bn2.weight', 'embed_image.resnet.7.0.bn1.num_batches_tracked', 'embed_image.resnet.1.running_mean', 'embed_image.resnet.5.0.bn2.weight', 'embed_image.resnet.5.2.bn2.running_mean', 'embed_image.resnet.7.0.bn2.bias', 'embed_image.resnet.6.3.conv2.weight', 'embed_image.resnet.4.0.bn1.running_mean', 'embed_image.resnet.5.1.bn3.running_var', 'embed_image.resnet.6.1.bn3.weight', 'embed_image.resnet.6.3.bn3.running_mean', 'embed_image.resnet.6.3.bn1.bias', 'embed_image.resnet.4.0.downsample.0.weight', 'embed_image.resnet.6.2.bn3.weight', 'embed_image.resnet.7.2.bn2.running_var', 'embed_image.resnet.6.1.bn1.weight', 'embed_image.resnet.4.2.bn2.weight', 'embed_image.resnet.4.2.bn1.bias', 'embed_image.resnet.7.0.bn2.running_mean', 'embed_image.resnet.5.2.bn1.num_batches_tracked', 'embed_image.resnet.7.0.conv1.weight', 'embed_image.resnet.6.1.conv2.weight', 'embed_image.resnet.6.3.bn2.running_var', 'embed_image.resnet.6.4.bn2.running_mean', 'embed_image.resnet.7.2.bn2.running_mean', 'embed_image.resnet.6.2.bn2.num_batches_tracked', 'embed_image.resnet.4.0.bn2.num_batches_tracked', 'embed_image.resnet.5.0.downsample.1.bias', 'embed_image.resnet.4.1.bn2.num_batches_tracked', 'embed_image.resnet.7.0.bn1.running_var', 'embed_image.resnet.4.0.bn3.running_mean', 'embed_image.resnet.6.1.bn1.running_mean', 'embed_image.resnet.5.3.bn3.running_var', 'embed_image.resnet.4.0.conv3.weight', 'embed_image.resnet.4.0.bn3.bias', 'embed_image.resnet.6.5.conv2.weight', 'embed_image.resnet.6.1.bn1.running_var', 'embed_image.resnet.6.5.conv3.weight', 'embed_image.resnet.4.0.downsample.1.num_batches_tracked', 'embed_image.resnet.6.5.bn2.num_batches_tracked', 'embed_image.resnet.4.1.bn3.weight', 'embed_image.resnet.6.5.bn3.bias', 'embed_image.resnet.6.0.conv1.weight', 'embed_image.resnet.5.2.bn2.num_batches_tracked', 'embed_image.resnet.6.2.bn3.num_batches_tracked', 'embed_image.resnet.6.1.bn3.bias', 'embed_image.resnet.6.0.bn3.running_mean', 'embed_image.resnet.5.2.bn1.weight', 'embed_image.resnet.6.3.bn3.weight', 'embed_image.resnet.6.4.bn1.bias', 'embed_image.resnet.4.0.bn2.running_mean', 'embed_image.resnet.6.1.conv3.weight', 'embed_image.resnet.6.5.bn2.running_var', 'embed_image.resnet.5.3.bn3.bias', 'embed_image.resnet.5.0.bn3.running_var', 'embed_image.resnet.7.1.bn1.bias', 'embed_image.resnet.6.0.downsample.0.weight', 'embed_image.resnet.5.1.bn2.weight', 'embed_image.resnet.6.4.bn2.bias', 'embed_image.resnet.5.1.bn1.bias', 'embed_image.resnet.6.1.bn1.bias', 'embed_image.resnet.4.1.bn1.weight', 'embed_image.resnet.5.0.bn3.weight', 'embed_image.resnet.5.0.downsample.0.weight', 'embed_image.resnet.6.2.bn1.bias', 'embed_image.resnet.6.1.bn3.running_mean', 'embed_image.resnet.6.4.bn1.num_batches_tracked', 'embed_image.resnet.6.3.bn1.num_batches_tracked', 'embed_image.resnet.6.5.bn3.weight', 'embed_image.resnet.5.0.bn1.weight', 'embed_image.resnet.7.1.bn3.bias', 'embed_image.resnet.5.2.conv1.weight', 'embed_image.resnet.4.1.conv3.weight', 'embed_image.resnet.5.3.conv1.weight', 'embed_image.resnet.5.2.bn2.running_var', 'embed_image.resnet.5.3.bn2.num_batches_tracked', 'embed_image.resnet.6.5.bn3.running_mean', 'embed_image.resnet.6.5.bn1.bias', 'embed_image.resnet.5.0.bn3.bias', 'embed_image.resnet.7.0.downsample.1.running_var', 'embed_image.resnet.6.3.bn2.weight', 'embed_image.resnet.4.0.bn3.num_batches_tracked', 'embed_image.resnet.6.5.bn3.num_batches_tracked', 'embed_image.resnet.6.3.bn3.running_var', 'embed_image.resnet.4.1.bn3.num_batches_tracked', 'embed_image.resnet.5.1.bn1.weight', 'embed_image.resnet.6.3.bn3.bias', 'embed_image.resnet.7.0.downsample.0.weight', 'embed_image.resnet.4.1.bn3.bias', 'embed_image.resnet.4.2.conv2.weight', 'embed_image.resnet.5.0.bn2.bias', 'embed_image.resnet.5.1.bn2.num_batches_tracked', 'embed_image.resnet.0.weight', 'embed_image.resnet.6.4.bn1.running_var', 'embed_image.resnet.7.2.bn1.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Loading checkpoint shards: 100%|██████████| 2/2 [00:12<00:00,  5.84s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:12<00:00,  6.44s/it]
Some weights of TrueReader were not initialized from the model checkpoint at /home/jaded79/visual-check/llama_weights/ and are newly initialized: ['embed_image.resnet.6.2.conv3.weight', 'embed_image.resnet.5.2.bn1.running_var', 'embed_image.resnet.5.0.bn2.running_mean', 'embed_image.resnet.5.2.bn2.num_batches_tracked', 'embed_image.resnet.7.0.bn2.bias', 'embed_image.resnet.4.0.bn3.running_var', 'embed_image.resnet.7.1.bn1.running_mean', 'embed_image.resnet.6.3.bn3.running_mean', 'embed_image.resnet.5.3.bn2.running_var', 'embed_image.resnet.7.0.bn3.num_batches_tracked', 'embed_image.resnet.4.2.bn3.weight', 'embed_image.resnet.6.0.downsample.1.bias', 'embed_image.resnet.4.0.downsample.1.running_var', 'embed_image.resnet.6.3.bn3.num_batches_tracked', 'embed_image.resnet.7.0.conv2.weight', 'embed_image.resnet.6.0.bn2.running_var', 'embed_image.resnet.4.0.bn2.bias', 'embed_image.resnet.7.2.bn1.running_var', 'embed_image.resnet.6.2.bn3.running_var', 'embed_image.resnet.7.2.bn3.bias', 'embed_image.resnet.6.1.conv1.weight', 'embed_image.resnet.7.2.bn2.bias', 'embed_image.resnet.7.2.bn2.running_var', 'embed_image.resnet.6.2.conv1.weight', 'embed_image.resnet.5.1.bn3.bias', 'embed_image.resnet.6.4.bn1.weight', 'embed_image.resnet.6.3.conv3.weight', 'embed_image.resnet.6.5.bn2.running_mean', 'embed_image.resnet.6.2.conv2.weight', 'embed_image.resnet.6.5.bn1.weight', 'embed_image.resnet.1.running_mean', 'embed_image.resnet.6.5.bn1.running_var', 'embed_image.resnet.4.2.conv3.weight', 'embed_image.resnet.6.2.bn2.running_mean', 'embed_image.resnet.6.0.bn2.running_mean', 'embed_image.resnet.6.1.bn1.bias', 'embed_image.resnet.7.0.conv1.weight', 'embed_image.resnet.6.0.conv3.weight', 'embed_image.resnet.6.2.bn1.num_batches_tracked', 'embed_image.resnet.6.2.bn1.bias', 'embed_image.resnet.6.1.bn3.num_batches_tracked', 'embed_image.resnet.4.0.downsample.1.running_mean', 'embed_image.resnet.6.0.bn3.running_mean', 'embed_image.resnet.5.3.bn2.num_batches_tracked', 'embed_image.resnet.5.3.bn1.bias', 'embed_image.resnet.5.2.bn2.bias', 'embed_image.resnet.4.0.bn2.running_mean', 'embed_image.resnet.6.2.bn3.weight', 'embed_image.resnet.5.3.bn2.running_mean', 'embed_image.resnet.6.5.bn3.running_var', 'embed_image.resnet.4.2.conv2.weight', 'embed_image.resnet.4.1.bn3.weight', 'embeddings_project.weight', 'embed_image.resnet.5.3.conv1.weight', 'embed_image.resnet.6.0.bn3.num_batches_tracked', 'embed_image.resnet.7.0.downsample.1.num_batches_tracked', 'embed_image.resnet.4.0.bn1.bias', 'embed_image.resnet.7.0.bn3.weight', 'embed_image.resnet.6.0.bn3.running_var', 'embed_image.resnet.6.4.conv3.weight', 'embed_image.resnet.4.0.downsample.1.weight', 'embed_image.resnet.6.0.downsample.1.num_batches_tracked', 'embed_image.resnet.6.0.bn1.weight', 'embed_image.resnet.6.2.bn1.running_mean', 'embed_image.resnet.6.4.bn1.running_var', 'embed_image.resnet.7.2.bn1.weight', 'embed_image.resnet.5.1.conv1.weight', 'embed_image.resnet.5.3.bn1.num_batches_tracked', 'embed_image.resnet.6.1.bn2.num_batches_tracked', 'embed_image.resnet.4.1.bn3.bias', 'embed_image.resnet.6.5.bn2.bias', 'embed_image.resnet.6.5.conv1.weight', 'embed_image.resnet.7.1.bn2.num_batches_tracked', 'embed_image.resnet.5.3.bn1.running_mean', 'embed_image.resnet.4.0.conv1.weight', 'embed_image.resnet.6.5.bn1.running_mean', 'embed_image.resnet.7.0.bn1.weight', 'embed_image.resnet.7.2.bn2.running_mean', 'embed_image.resnet.4.1.bn3.running_mean', 'embed_image.resnet.4.2.bn3.bias', 'embed_image.resnet.4.1.bn1.weight', 'embed_image.resnet.4.2.bn2.num_batches_tracked', 'embed_image.resnet.6.1.conv3.weight', 'embed_image.resnet.4.1.bn2.bias', 'embed_image.resnet.4.1.bn1.running_mean', 'embed_image.resnet.1.running_var', 'embed_image.resnet.6.2.bn2.weight', 'embed_image.resnet.5.1.bn2.running_mean', 'embed_image.resnet.6.4.bn3.running_mean', 'embed_image.resnet.4.1.bn1.num_batches_tracked', 'embed_image.resnet.5.0.bn3.running_var', 'embed_image.resnet.4.1.bn2.num_batches_tracked', 'embed_image.resnet.5.3.conv3.weight', 'embed_image.resnet.7.0.bn3.bias', 'embed_image.resnet.6.4.bn1.running_mean', 'embed_image.resnet.7.0.bn2.weight', 'embed_image.resnet.6.1.bn2.running_mean', 'embed_image.resnet.6.2.bn2.running_var', 'embed_image.resnet.4.1.conv1.weight', 'embed_image.resnet.6.0.bn1.bias', 'embed_image.resnet.5.3.bn3.num_batches_tracked', 'embed_image.resnet.6.0.conv2.weight', 'embed_image.resnet.4.0.bn1.running_var', 'embed_image.resnet.5.0.bn2.bias', 'embed_image.resnet.4.0.downsample.0.weight', 'embeddings_project.bias', 'embed_image.resnet.6.3.bn1.running_mean', 'embed_image.resnet.4.2.bn1.weight', 'embed_image.resnet.6.3.bn3.running_var', 'embed_image.resnet.6.5.bn3.bias', 'embed_image.resnet.5.1.bn1.running_mean', 'embed_image.resnet.6.3.conv2.weight', 'embed_image.resnet.5.3.bn3.bias', 'embed_image.resnet.5.2.bn1.running_mean', 'embed_image.resnet.5.0.bn1.num_batches_tracked', 'embed_image.resnet.4.1.bn1.running_var', 'embed_image.resnet.7.1.bn1.weight', 'embed_image.resnet.5.2.bn2.running_mean', 'embed_image.resnet.6.5.bn2.running_var', 'embed_image.resnet.5.1.bn2.running_var', 'embed_image.resnet.6.2.bn2.bias', 'embed_image.resnet.6.2.bn1.weight', 'embed_image.resnet.5.3.conv2.weight', 'embed_image.resnet.0.weight', 'embed_image.resnet.7.2.bn1.running_mean', 'embed_image.resnet.5.1.bn1.running_var', 'embed_image.resnet.7.1.bn3.bias', 'embed_image.resnet.4.2.conv1.weight', 'embed_image.resnet.5.1.bn1.num_batches_tracked', 'embed_image.resnet.4.0.bn3.weight', 'embed_image.resnet.4.2.bn3.running_mean', 'embed_image.resnet.5.0.downsample.1.bias', 'embed_image.resnet.5.3.bn2.weight', 'embed_image.resnet.7.2.bn2.num_batches_tracked', 'embed_image.resnet.4.0.bn3.running_mean', 'embed_image.resnet.7.0.bn1.running_var', 'embed_image.resnet.7.2.conv1.weight', 'embed_image.resnet.6.4.conv1.weight', 'embed_image.resnet.6.0.bn3.weight', 'embed_image.resnet.5.3.bn3.running_mean', 'embed_image.resnet.7.0.bn2.num_batches_tracked', 'embed_image.resnet.6.4.bn1.bias', 'embed_image.resnet.5.0.bn1.running_mean', 'embed_image.resnet.6.1.bn2.bias', 'embed_image.resnet.7.0.downsample.1.running_mean', 'embed_image.resnet.6.0.bn1.num_batches_tracked', 'embed_image.resnet.7.0.bn3.running_var', 'embed_image.resnet.7.0.downsample.0.weight', 'embed_image.resnet.5.3.bn3.running_var', 'embed_image.resnet.4.0.bn2.running_var', 'embed_image.resnet.6.4.bn2.bias', 'embed_image.resnet.5.0.bn2.num_batches_tracked', 'embed_image.resnet.7.2.conv2.weight', 'embed_image.resnet.4.0.bn1.running_mean', 'embed_image.resnet.6.5.bn2.weight', 'embed_image.resnet.5.2.bn3.running_mean', 'embed_image.resnet.5.3.bn2.bias', 'embed_image.resnet.6.4.bn1.num_batches_tracked', 'embed_image.resnet.6.4.bn2.weight', 'embed_image.resnet.5.2.bn3.num_batches_tracked', 'embed_image.resnet.7.1.conv2.weight', 'embed_image.resnet.4.2.bn2.running_mean', 'embed_image.resnet.6.1.bn3.running_var', 'embed_image.resnet.7.0.bn1.running_mean', 'embed_image.resnet.6.1.bn2.weight', 'embed_image.resnet.4.0.downsample.1.num_batches_tracked', 'embed_image.resnet.7.1.bn3.weight', 'embed_image.resnet.5.2.bn1.weight', 'embed_image.resnet.5.0.conv2.weight', 'embed_image.resnet.6.1.bn3.bias', 'embed_image.resnet.6.4.bn3.weight', 'embed_image.resnet.5.0.bn2.weight', 'embed_image.resnet.5.0.downsample.0.weight', 'embed_image.resnet.5.0.downsample.1.running_mean', 'embed_image.resnet.6.3.bn2.bias', 'embed_image.resnet.6.4.bn2.running_mean', 'embed_image.resnet.6.1.bn1.weight', 'embed_image.resnet.5.0.bn1.running_var', 'embed_image.resnet.4.0.bn2.num_batches_tracked', 'embed_image.resnet.5.1.bn3.running_mean', 'embed_image.resnet.6.0.downsample.1.running_mean', 'embed_image.resnet.6.1.bn1.running_mean', 'embed_image.resnet.6.5.bn3.num_batches_tracked', 'embed_image.resnet.6.2.bn3.num_batches_tracked', 'embed_image.resnet.5.2.bn3.running_var', 'embed_image.resnet.6.5.conv3.weight', 'embed_image.resnet.5.1.conv3.weight', 'embed_image.resnet.4.2.bn1.num_batches_tracked', 'embed_image.resnet.6.0.bn2.weight', 'embed_image.resnet.5.3.bn1.running_var', 'embed_image.resnet.7.1.bn1.num_batches_tracked', 'embed_image.resnet.4.0.bn2.weight', 'embed_image.resnet.6.0.bn1.running_var', 'embed_image.resnet.7.2.bn3.num_batches_tracked', 'embed_image.resnet.6.3.bn3.bias', 'embed_image.resnet.7.0.downsample.1.bias', 'embed_image.resnet.4.0.conv2.weight', 'embed_image.resnet.5.0.conv1.weight', 'embed_image.resnet.7.2.bn3.weight', 'embed_image.resnet.4.0.bn1.num_batches_tracked', 'embed_image.resnet.5.2.bn3.bias', 'embed_image.resnet.6.3.bn3.weight', 'embed_image.resnet.4.2.bn1.running_mean', 'embed_image.resnet.4.2.bn1.running_var', 'embed_image.resnet.6.0.downsample.0.weight', 'embed_image.resnet.4.0.downsample.1.bias', 'embed_image.resnet.5.1.bn3.weight', 'embed_image.resnet.5.0.bn1.weight', 'embed_image.resnet.6.0.bn3.bias', 'embed_image.resnet.6.4.bn2.num_batches_tracked', 'embed_image.resnet.7.2.bn3.running_var', 'embed_image.resnet.7.0.bn2.running_var', 'embed_image.resnet.5.1.bn2.weight', 'embed_image.resnet.7.1.bn3.running_var', 'embed_image.resnet.6.0.downsample.1.weight', 'embed_image.resnet.7.1.bn3.running_mean', 'embed_image.resnet.5.0.bn3.weight', 'embed_image.resnet.4.1.bn2.running_mean', 'embed_image.resnet.5.0.bn3.bias', 'embed_image.resnet.7.1.bn1.running_var', 'embed_image.resnet.5.2.bn3.weight', 'embed_image.resnet.5.1.bn2.num_batches_tracked', 'embed_image.resnet.7.2.bn1.bias', 'embed_image.resnet.6.1.bn3.weight', 'embed_image.resnet.5.0.downsample.1.num_batches_tracked', 'embed_image.resnet.7.1.bn2.bias', 'embed_image.resnet.6.3.conv1.weight', 'embed_image.resnet.6.5.bn3.running_mean', 'embed_image.resnet.6.0.downsample.1.running_var', 'embed_image.resnet.7.0.bn3.running_mean', 'embed_image.resnet.5.1.conv2.weight', 'embed_image.resnet.7.1.conv3.weight', 'embed_image.resnet.1.weight', 'embed_image.resnet.6.1.bn1.num_batches_tracked', 'embed_image.resnet.5.1.bn3.running_var', 'embed_image.resnet.5.2.conv2.weight', 'embed_image.resnet.6.0.bn1.running_mean', 'embed_image.resnet.5.0.bn3.num_batches_tracked', 'embed_image.resnet.4.1.conv3.weight', 'embed_image.resnet.6.4.conv2.weight', 'embed_image.resnet.6.5.bn3.weight', 'embed_image.resnet.6.3.bn1.running_var', 'embed_image.resnet.6.3.bn1.weight', 'embed_image.resnet.5.0.bn2.running_var', 'embed_image.resnet.6.2.bn3.bias', 'embed_image.resnet.5.0.downsample.1.running_var', 'embed_image.resnet.4.1.bn3.num_batches_tracked', 'embed_image.resnet.7.0.downsample.1.weight', 'embed_image.resnet.6.4.bn3.running_var', 'embed_image.resnet.5.1.bn2.bias', 'embed_image.resnet.4.2.bn2.weight', 'embed_image.resnet.5.0.bn3.running_mean', 'embed_image.resnet.7.2.bn1.num_batches_tracked', 'embed_image.resnet.7.1.bn3.num_batches_tracked', 'embed_image.resnet.5.2.conv3.weight', 'embed_image.resnet.5.1.bn1.weight', 'embed_image.resnet.4.2.bn2.running_var', 'embed_image.resnet.5.2.bn2.weight', 'embed_image.resnet.5.1.bn1.bias', 'embed_image.resnet.6.5.conv2.weight', 'embed_image.resnet.5.2.conv1.weight', 'embed_image.resnet.6.2.bn1.running_var', 'embed_image.resnet.6.3.bn1.bias', 'embed_image.resnet.7.1.bn2.weight', 'embed_image.resnet.7.1.bn2.running_mean', 'embed_image.resnet.4.2.bn2.bias', 'embed_image.resnet.6.3.bn1.num_batches_tracked', 'embed_image.resnet.4.0.bn3.num_batches_tracked', 'embed_image.resnet.5.1.bn3.num_batches_tracked', 'embed_image.resnet.6.2.bn2.num_batches_tracked', 'embed_image.resnet.7.0.bn2.running_mean', 'embed_image.resnet.7.0.bn1.bias', 'embed_image.resnet.5.3.bn3.weight', 'embed_image.resnet.6.0.bn2.num_batches_tracked', 'embed_image.resnet.4.1.bn2.weight', 'embed_image.resnet.6.5.bn1.bias', 'embed_image.resnet.6.2.bn3.running_mean', 'embed_image.resnet.4.0.bn3.bias', 'embed_image.resnet.1.bias', 'embed_image.resnet.5.3.bn1.weight', 'embed_image.resnet.7.1.bn2.running_var', 'embed_image.resnet.6.1.bn1.running_var', 'embed_image.resnet.6.0.bn2.bias', 'embed_image.resnet.5.2.bn1.num_batches_tracked', 'embed_image.resnet.5.0.conv3.weight', 'embed_image.resnet.5.0.downsample.1.weight', 'embed_image.resnet.6.3.bn2.num_batches_tracked', 'embed_image.resnet.6.1.bn3.running_mean', 'embed_image.resnet.6.0.conv1.weight', 'embed_image.resnet.6.5.bn2.num_batches_tracked', 'embed_image.resnet.4.0.conv3.weight', 'embed_image.resnet.4.1.bn1.bias', 'embed_image.resnet.7.0.bn1.num_batches_tracked', 'embed_image.resnet.6.1.bn2.running_var', 'embed_image.resnet.7.1.bn1.bias', 'embed_image.resnet.4.1.conv2.weight', 'embed_image.resnet.4.2.bn1.bias', 'embed_image.resnet.6.4.bn2.running_var', 'embed_image.resnet.4.2.bn3.num_batches_tracked', 'embed_image.resnet.6.4.bn3.num_batches_tracked', 'embed_image.resnet.4.2.bn3.running_var', 'embed_image.resnet.6.4.bn3.bias', 'embed_image.resnet.7.2.bn2.weight', 'embed_image.resnet.7.2.bn3.running_mean', 'embed_image.resnet.7.1.conv1.weight', 'embed_image.resnet.7.0.downsample.1.running_var', 'embed_image.resnet.6.3.bn2.running_var', 'embed_image.resnet.4.0.bn1.weight', 'embed_image.resnet.5.0.bn1.bias', 'embed_image.resnet.4.1.bn2.running_var', 'embed_image.resnet.7.0.conv3.weight', 'embed_image.resnet.1.num_batches_tracked', 'embed_image.resnet.6.5.bn1.num_batches_tracked', 'embed_image.resnet.6.1.conv2.weight', 'embed_image.resnet.5.2.bn2.running_var', 'embed_image.resnet.6.3.bn2.running_mean', 'embed_image.resnet.6.3.bn2.weight', 'embed_image.resnet.7.2.conv3.weight', 'embed_image.resnet.5.2.bn1.bias', 'embed_image.resnet.4.1.bn3.running_var']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
Using pad_token, but it is not set yet.
Using pad_token, but it is not set yet.
/home/jaded79/.conda/envs/mmcoder/lib/python3.11/site-packages/torch/distributed/fsdp/_wrap_utils.py:65: UserWarning: Both mixed precision and an `auto_wrap_policy` were specified for FSDP, where the wrapped module has batch norm submodules. The batch norm submodules will be wrapped as separate FSDP instances with mixed precision disabled since some batch norm kernels do not support low precision.
  warnings.warn(
/home/jaded79/.conda/envs/mmcoder/lib/python3.11/site-packages/torch/distributed/fsdp/_wrap_utils.py:65: UserWarning: Both mixed precision and an `auto_wrap_policy` were specified for FSDP, where the wrapped module has batch norm submodules. The batch norm submodules will be wrapped as separate FSDP instances with mixed precision disabled since some batch norm kernels do not support low precision.
  warnings.warn(
in dataloader. input shape: torch.Size([9]), image shape: torch.Size([3, 224, 224])
in dataloader. input shape: torch.Size([9]), image shape: torch.Size([3, 224, 224])
in collator. input_ids shape: torch.Size([2, 9]), attention_mask shape: torch.Size([2, 9]), images shape: torch.Size([2, 3, 224, 224])
wandb: Tracking run with wandb version 0.13.10
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
  0%|          | 0/4029 [00:00<?, ?it/s]in dataloader. input shape: torch.Size([9]), image shape: torch.Size([3, 224, 224])
in dataloader. input shape: torch.Size([9]), image shape: torch.Size([3, 224, 224])
in collator. input_ids shape: torch.Size([2, 9]), attention_mask shape: torch.Size([2, 9]), images shape: torch.Size([2, 3, 224, 224])
in forward pass. input_ids size before embedding: torch.Size([2, 9])
in forward pass. input_ids size before embedding: torch.Size([2, 9])
In forward pass. text embeddings: torch.Size([2, 9, 4096]), image embeddings: torch.Size([2, 2048])
resized image embeddings: torch.Size([2, 9, 2048])
In forward pass. text embeddings: torch.Size([2, 9, 4096]), image embeddings: torch.Size([2, 2048])
resized image embeddings: torch.Size([2, 9, 2048])
in forward pass. input_ids size before embedding: torch.Size([2, 10])
in forward pass. input_ids size before embedding: torch.Size([2, 10])
In forward pass. text embeddings: torch.Size([2, 10, 4096]), image embeddings: torch.Size([2, 2048])
resized image embeddings: torch.Size([2, 10, 2048])
In forward pass. text embeddings: torch.Size([2, 10, 4096]), image embeddings: torch.Size([2, 2048])
resized image embeddings: torch.Size([2, 10, 2048])
in forward pass. input_ids size before embedding: torch.Size([2, 11])
in forward pass. input_ids size before embedding: torch.Size([2, 11])
In forward pass. text embeddings: torch.Size([2, 11, 4096]), image embeddings: torch.Size([2, 2048])
resized image embeddings: torch.Size([2, 11, 2048])
In forward pass. text embeddings: torch.Size([2, 11, 4096]), image embeddings: torch.Size([2, 2048])
resized image embeddings: torch.Size([2, 11, 2048])
in forward pass. input_ids size before embedding: torch.Size([2, 12])
in forward pass. input_ids size before embedding: torch.Size([2, 12])
In forward pass. text embeddings: torch.Size([2, 12, 4096]), image embeddings: torch.Size([2, 2048])
resized image embeddings: torch.Size([2, 12, 2048])
In forward pass. text embeddings: torch.Size([2, 12, 4096]), image embeddings: torch.Size([2, 2048])
resized image embeddings: torch.Size([2, 12, 2048])
in forward pass. input_ids size before embedding: torch.Size([2, 13])
in forward pass. input_ids size before embedding: torch.Size([2, 13])
In forward pass. text embeddings: torch.Size([2, 13, 4096]), image embeddings: torch.Size([2, 2048])
resized image embeddings: torch.Size([2, 13, 2048])
In forward pass. text embeddings: torch.Size([2, 13, 4096]), image embeddings: torch.Size([2, 2048])
resized image embeddings: torch.Size([2, 13, 2048])
in forward pass. input_ids size before embedding: torch.Size([2, 14])
in forward pass. input_ids size before embedding: torch.Size([2, 14])
In forward pass. text embeddings: torch.Size([2, 14, 4096]), image embeddings: torch.Size([2, 2048])
resized image embeddings: torch.Size([2, 14, 2048])
In forward pass. text embeddings: torch.Size([2, 14, 4096]), image embeddings: torch.Size([2, 2048])
resized image embeddings: torch.Size([2, 14, 2048])
in forward pass. input_ids size before embedding: torch.Size([2, 15])
in forward pass. input_ids size before embedding: torch.Size([2, 15])
In forward pass. text embeddings: torch.Size([2, 15, 4096]), image embeddings: torch.Size([2, 2048])
resized image embeddings: torch.Size([2, 15, 2048])
In forward pass. text embeddings: torch.Size([2, 15, 4096]), image embeddings: torch.Size([2, 2048])
resized image embeddings: torch.Size([2, 15, 2048])
in forward pass. input_ids size before embedding: torch.Size([2, 16])
in forward pass. input_ids size before embedding: torch.Size([2, 16])
In forward pass. text embeddings: torch.Size([2, 16, 4096]), image embeddings: torch.Size([2, 2048])
resized image embeddings: torch.Size([2, 16, 2048])
In forward pass. text embeddings: torch.Size([2, 16, 4096]), image embeddings: torch.Size([2, 2048])
resized image embeddings: torch.Size([2, 16, 2048])
in forward pass. input_ids size before embedding: torch.Size([2, 17])
in forward pass. input_ids size before embedding: torch.Size([2, 17])
In forward pass. text embeddings: torch.Size([2, 17, 4096]), image embeddings: torch.Size([2, 2048])
resized image embeddings: torch.Size([2, 17, 2048])
In forward pass. text embeddings: torch.Size([2, 17, 4096]), image embeddings: torch.Size([2, 2048])
resized image embeddings: torch.Size([2, 17, 2048])
in forward pass. input_ids size before embedding: torch.Size([2, 18])
in forward pass. input_ids size before embedding: torch.Size([2, 18])
In forward pass. text embeddings: torch.Size([2, 18, 4096]), image embeddings: torch.Size([2, 2048])
resized image embeddings: torch.Size([2, 18, 2048])
In forward pass. text embeddings: torch.Size([2, 18, 4096]), image embeddings: torch.Size([2, 2048])
resized image embeddings: torch.Size([2, 18, 2048])
in forward pass. input_ids size before embedding: torch.Size([2, 19])
in forward pass. input_ids size before embedding: torch.Size([2, 19])
In forward pass. text embeddings: torch.Size([2, 19, 4096]), image embeddings: torch.Size([2, 2048])
resized image embeddings: torch.Size([2, 19, 2048])
In forward pass. text embeddings: torch.Size([2, 19, 4096]), image embeddings: torch.Size([2, 2048])
resized image embeddings: torch.Size([2, 19, 2048])
in forward pass. input_ids size before embedding: torch.Size([2, 20])
in forward pass. input_ids size before embedding: torch.Size([2, 20])
In forward pass. text embeddings: torch.Size([2, 20, 4096]), image embeddings: torch.Size([2, 2048])
resized image embeddings: torch.Size([2, 20, 2048])
In forward pass. text embeddings: torch.Size([2, 20, 4096]), image embeddings: torch.Size([2, 2048])
resized image embeddings: torch.Size([2, 20, 2048])
in forward pass. input_ids size before embedding: torch.Size([2, 21])
in forward pass. input_ids size before embedding: torch.Size([2, 21])
In forward pass. text embeddings: torch.Size([2, 21, 4096]), image embeddings: torch.Size([2, 2048])
resized image embeddings: torch.Size([2, 21, 2048])
In forward pass. text embeddings: torch.Size([2, 21, 4096]), image embeddings: torch.Size([2, 2048])
resized image embeddings: torch.Size([2, 21, 2048])
in forward pass. input_ids size before embedding: torch.Size([2, 22])
in forward pass. input_ids size before embedding: torch.Size([2, 22])
In forward pass. text embeddings: torch.Size([2, 22, 4096]), image embeddings: torch.Size([2, 2048])
resized image embeddings: torch.Size([2, 22, 2048])
In forward pass. text embeddings: torch.Size([2, 22, 4096]), image embeddings: torch.Size([2, 2048])
resized image embeddings: torch.Size([2, 22, 2048])
in forward pass. input_ids size before embedding: torch.Size([2, 23])
in forward pass. input_ids size before embedding: torch.Size([2, 23])
In forward pass. text embeddings: torch.Size([2, 23, 4096]), image embeddings: torch.Size([2, 2048])
resized image embeddings: torch.Size([2, 23, 2048])
In forward pass. text embeddings: torch.Size([2, 23, 4096]), image embeddings: torch.Size([2, 2048])
resized image embeddings: torch.Size([2, 23, 2048])
in forward pass. input_ids size before embedding: torch.Size([2, 24])
in forward pass. input_ids size before embedding: torch.Size([2, 24])
In forward pass. text embeddings: torch.Size([2, 24, 4096]), image embeddings: torch.Size([2, 2048])
resized image embeddings: torch.Size([2, 24, 2048])
In forward pass. text embeddings: torch.Size([2, 24, 4096]), image embeddings: torch.Size([2, 2048])
resized image embeddings: torch.Size([2, 24, 2048])
in forward pass. input_ids size before embedding: torch.Size([2, 25])
in forward pass. input_ids size before embedding: torch.Size([2, 25])
In forward pass. text embeddings: torch.Size([2, 25, 4096]), image embeddings: torch.Size([2, 2048])
resized image embeddings: torch.Size([2, 25, 2048])
In forward pass. text embeddings: torch.Size([2, 25, 4096]), image embeddings: torch.Size([2, 2048])
resized image embeddings: torch.Size([2, 25, 2048])
in forward pass. input_ids size before embedding: torch.Size([2, 26])
in forward pass. input_ids size before embedding: torch.Size([2, 26])
In forward pass. text embeddings: torch.Size([2, 26, 4096]), image embeddings: torch.Size([2, 2048])
resized image embeddings: torch.Size([2, 26, 2048])
In forward pass. text embeddings: torch.Size([2, 26, 4096]), image embeddings: torch.Size([2, 2048])
resized image embeddings: torch.Size([2, 26, 2048])
in forward pass. input_ids size before embedding: torch.Size([2, 27])
in forward pass. input_ids size before embedding: torch.Size([2, 27])
In forward pass. text embeddings: torch.Size([2, 27, 4096]), image embeddings: torch.Size([2, 2048])
resized image embeddings: torch.Size([2, 27, 2048])
In forward pass. text embeddings: torch.Size([2, 27, 4096]), image embeddings: torch.Size([2, 2048])
resized image embeddings: torch.Size([2, 27, 2048])
in forward pass. input_ids size before embedding: torch.Size([2, 28])
in forward pass. input_ids size before embedding: torch.Size([2, 28])
In forward pass. text embeddings: torch.Size([2, 28, 4096]), image embeddings: torch.Size([2, 2048])
resized image embeddings: torch.Size([2, 28, 2048])
In forward pass. text embeddings: torch.Size([2, 28, 4096]), image embeddings: torch.Size([2, 2048])
resized image embeddings: torch.Size([2, 28, 2048])
in forward pass. input_ids size before embedding: torch.Size([2, 29])
in forward pass. input_ids size before embedding: torch.Size([2, 29])
In forward pass. text embeddings: torch.Size([2, 29, 4096]), image embeddings: torch.Size([2, 2048])
resized image embeddings: torch.Size([2, 29, 2048])
In forward pass. text embeddings: torch.Size([2, 29, 4096]), image embeddings: torch.Size([2, 2048])
resized image embeddings: torch.Size([2, 29, 2048])
in forward pass. input_ids size before embedding: torch.Size([2, 30])
in forward pass. input_ids size before embedding: torch.Size([2, 30])
In forward pass. text embeddings: torch.Size([2, 30, 4096]), image embeddings: torch.Size([2, 2048])
resized image embeddings: torch.Size([2, 30, 2048])
In forward pass. text embeddings: torch.Size([2, 30, 4096]), image embeddings: torch.Size([2, 2048])
resized image embeddings: torch.Size([2, 30, 2048])
in forward pass. input_ids size before embedding: torch.Size([2, 31])
in forward pass. input_ids size before embedding: torch.Size([2, 31])
In forward pass. text embeddings: torch.Size([2, 31, 4096]), image embeddings: torch.Size([2, 2048])
resized image embeddings: torch.Size([2, 31, 2048])
In forward pass. text embeddings: torch.Size([2, 31, 4096]), image embeddings: torch.Size([2, 2048])
resized image embeddings: torch.Size([2, 31, 2048])
in forward pass. input_ids size before embedding: torch.Size([2, 32])
in forward pass. input_ids size before embedding: torch.Size([2, 32])
In forward pass. text embeddings: torch.Size([2, 32, 4096]), image embeddings: torch.Size([2, 2048])
resized image embeddings: torch.Size([2, 32, 2048])
In forward pass. text embeddings: torch.Size([2, 32, 4096]), image embeddings: torch.Size([2, 2048])
resized image embeddings: torch.Size([2, 32, 2048])
in forward pass. input_ids size before embedding: torch.Size([2, 33])
in forward pass. input_ids size before embedding: torch.Size([2, 33])
In forward pass. text embeddings: torch.Size([2, 33, 4096]), image embeddings: torch.Size([2, 2048])
resized image embeddings: torch.Size([2, 33, 2048])
In forward pass. text embeddings: torch.Size([2, 33, 4096]), image embeddings: torch.Size([2, 2048])
resized image embeddings: torch.Size([2, 33, 2048])
in forward pass. input_ids size before embedding: torch.Size([2, 34])
in forward pass. input_ids size before embedding: torch.Size([2, 34])
In forward pass. text embeddings: torch.Size([2, 34, 4096]), image embeddings: torch.Size([2, 2048])
resized image embeddings: torch.Size([2, 34, 2048])
In forward pass. text embeddings: torch.Size([2, 34, 4096]), image embeddings: torch.Size([2, 2048])
resized image embeddings: torch.Size([2, 34, 2048])
in forward pass. input_ids size before embedding: torch.Size([2, 35])
in forward pass. input_ids size before embedding: torch.Size([2, 35])
In forward pass. text embeddings: torch.Size([2, 35, 4096]), image embeddings: torch.Size([2, 2048])
resized image embeddings: torch.Size([2, 35, 2048])
In forward pass. text embeddings: torch.Size([2, 35, 4096]), image embeddings: torch.Size([2, 2048])
resized image embeddings: torch.Size([2, 35, 2048])
in forward pass. input_ids size before embedding: torch.Size([2, 36])
in forward pass. input_ids size before embedding: torch.Size([2, 36])
In forward pass. text embeddings: torch.Size([2, 36, 4096]), image embeddings: torch.Size([2, 2048])
resized image embeddings: torch.Size([2, 36, 2048])
In forward pass. text embeddings: torch.Size([2, 36, 4096]), image embeddings: torch.Size([2, 2048])
resized image embeddings: torch.Size([2, 36, 2048])
in forward pass. input_ids size before embedding: torch.Size([2, 37])
in forward pass. input_ids size before embedding: torch.Size([2, 37])
In forward pass. text embeddings: torch.Size([2, 37, 4096]), image embeddings: torch.Size([2, 2048])
resized image embeddings: torch.Size([2, 37, 2048])
In forward pass. text embeddings: torch.Size([2, 37, 4096]), image embeddings: torch.Size([2, 2048])
resized image embeddings: torch.Size([2, 37, 2048])
in forward pass. input_ids size before embedding: torch.Size([2, 38])
in forward pass. input_ids size before embedding: torch.Size([2, 38])
In forward pass. text embeddings: torch.Size([2, 38, 4096]), image embeddings: torch.Size([2, 2048])
resized image embeddings: torch.Size([2, 38, 2048])
In forward pass. text embeddings: torch.Size([2, 38, 4096]), image embeddings: torch.Size([2, 2048])
resized image embeddings: torch.Size([2, 38, 2048])
in forward pass. input_ids size before embedding: torch.Size([2, 39])
in forward pass. input_ids size before embedding: torch.Size([2, 39])
In forward pass. text embeddings: torch.Size([2, 39, 4096]), image embeddings: torch.Size([2, 2048])
resized image embeddings: torch.Size([2, 39, 2048])
In forward pass. text embeddings: torch.Size([2, 39, 4096]), image embeddings: torch.Size([2, 2048])
resized image embeddings: torch.Size([2, 39, 2048])
in forward pass. input_ids size before embedding: torch.Size([2, 40])
in forward pass. input_ids size before embedding: torch.Size([2, 40])
In forward pass. text embeddings: torch.Size([2, 40, 4096]), image embeddings: torch.Size([2, 2048])
resized image embeddings: torch.Size([2, 40, 2048])
In forward pass. text embeddings: torch.Size([2, 40, 4096]), image embeddings: torch.Size([2, 2048])
resized image embeddings: torch.Size([2, 40, 2048])
in forward pass. input_ids size before embedding: torch.Size([2, 41])
in forward pass. input_ids size before embedding: torch.Size([2, 41])
In forward pass. text embeddings: torch.Size([2, 41, 4096]), image embeddings: torch.Size([2, 2048])
resized image embeddings: torch.Size([2, 41, 2048])
In forward pass. text embeddings: torch.Size([2, 41, 4096]), image embeddings: torch.Size([2, 2048])
resized image embeddings: torch.Size([2, 41, 2048])
in forward pass. input_ids size before embedding: torch.Size([2, 42])
in forward pass. input_ids size before embedding: torch.Size([2, 42])
In forward pass. text embeddings: torch.Size([2, 42, 4096]), image embeddings: torch.Size([2, 2048])
resized image embeddings: torch.Size([2, 42, 2048])
In forward pass. text embeddings: torch.Size([2, 42, 4096]), image embeddings: torch.Size([2, 2048])
resized image embeddings: torch.Size([2, 42, 2048])
in forward pass. input_ids size before embedding: torch.Size([2, 43])
in forward pass. input_ids size before embedding: torch.Size([2, 43])
In forward pass. text embeddings: torch.Size([2, 43, 4096]), image embeddings: torch.Size([2, 2048])
resized image embeddings: torch.Size([2, 43, 2048])
In forward pass. text embeddings: torch.Size([2, 43, 4096]), image embeddings: torch.Size([2, 2048])
resized image embeddings: torch.Size([2, 43, 2048])
in forward pass. input_ids size before embedding: torch.Size([2, 44])
in forward pass. input_ids size before embedding: torch.Size([2, 44])
In forward pass. text embeddings: torch.Size([2, 44, 4096]), image embeddings: torch.Size([2, 2048])
resized image embeddings: torch.Size([2, 44, 2048])
In forward pass. text embeddings: torch.Size([2, 44, 4096]), image embeddings: torch.Size([2, 2048])
resized image embeddings: torch.Size([2, 44, 2048])
in forward pass. input_ids size before embedding: torch.Size([2, 45])
in forward pass. input_ids size before embedding: torch.Size([2, 45])
In forward pass. text embeddings: torch.Size([2, 45, 4096]), image embeddings: torch.Size([2, 2048])
resized image embeddings: torch.Size([2, 45, 2048])
In forward pass. text embeddings: torch.Size([2, 45, 4096]), image embeddings: torch.Size([2, 2048])
resized image embeddings: torch.Size([2, 45, 2048])
in forward pass. input_ids size before embedding: torch.Size([2, 46])
in forward pass. input_ids size before embedding: torch.Size([2, 46])
In forward pass. text embeddings: torch.Size([2, 46, 4096]), image embeddings: torch.Size([2, 2048])
resized image embeddings: torch.Size([2, 46, 2048])
In forward pass. text embeddings: torch.Size([2, 46, 4096]), image embeddings: torch.Size([2, 2048])
resized image embeddings: torch.Size([2, 46, 2048])
in forward pass. input_ids size before embedding: torch.Size([2, 47])
in forward pass. input_ids size before embedding: torch.Size([2, 47])
In forward pass. text embeddings: torch.Size([2, 47, 4096]), image embeddings: torch.Size([2, 2048])
resized image embeddings: torch.Size([2, 47, 2048])
In forward pass. text embeddings: torch.Size([2, 47, 4096]), image embeddings: torch.Size([2, 2048])
resized image embeddings: torch.Size([2, 47, 2048])
in forward pass. input_ids size before embedding: torch.Size([2, 48])
in forward pass. input_ids size before embedding: torch.Size([2, 48])
In forward pass. text embeddings: torch.Size([2, 48, 4096]), image embeddings: torch.Size([2, 2048])
resized image embeddings: torch.Size([2, 48, 2048])
In forward pass. text embeddings: torch.Size([2, 48, 4096]), image embeddings: torch.Size([2, 2048])
resized image embeddings: torch.Size([2, 48, 2048])
in forward pass. input_ids size before embedding: torch.Size([2, 49])
in forward pass. input_ids size before embedding: torch.Size([2, 49])
In forward pass. text embeddings: torch.Size([2, 49, 4096]), image embeddings: torch.Size([2, 2048])
resized image embeddings: torch.Size([2, 49, 2048])
In forward pass. text embeddings: torch.Size([2, 49, 4096]), image embeddings: torch.Size([2, 2048])
resized image embeddings: torch.Size([2, 49, 2048])
in forward pass. input_ids size before embedding: torch.Size([2, 50])
in forward pass. input_ids size before embedding: torch.Size([2, 50])
In forward pass. text embeddings: torch.Size([2, 50, 4096]), image embeddings: torch.Size([2, 2048])
resized image embeddings: torch.Size([2, 50, 2048])
In forward pass. text embeddings: torch.Size([2, 50, 4096]), image embeddings: torch.Size([2, 2048])
resized image embeddings: torch.Size([2, 50, 2048])
in forward pass. input_ids size before embedding: torch.Size([2, 51])
in forward pass. input_ids size before embedding: torch.Size([2, 51])
In forward pass. text embeddings: torch.Size([2, 51, 4096]), image embeddings: torch.Size([2, 2048])
resized image embeddings: torch.Size([2, 51, 2048])
In forward pass. text embeddings: torch.Size([2, 51, 4096]), image embeddings: torch.Size([2, 2048])
resized image embeddings: torch.Size([2, 51, 2048])
in forward pass. input_ids size before embedding: torch.Size([2, 52])
in forward pass. input_ids size before embedding: torch.Size([2, 52])
In forward pass. text embeddings: torch.Size([2, 52, 4096]), image embeddings: torch.Size([2, 2048])
resized image embeddings: torch.Size([2, 52, 2048])
In forward pass. text embeddings: torch.Size([2, 52, 4096]), image embeddings: torch.Size([2, 2048])
resized image embeddings: torch.Size([2, 52, 2048])
in forward pass. input_ids size before embedding: torch.Size([2, 53])
in forward pass. input_ids size before embedding: torch.Size([2, 53])
In forward pass. text embeddings: torch.Size([2, 53, 4096]), image embeddings: torch.Size([2, 2048])
resized image embeddings: torch.Size([2, 53, 2048])
In forward pass. text embeddings: torch.Size([2, 53, 4096]), image embeddings: torch.Size([2, 2048])
resized image embeddings: torch.Size([2, 53, 2048])
in forward pass. input_ids size before embedding: torch.Size([2, 54])
in forward pass. input_ids size before embedding: torch.Size([2, 54])
In forward pass. text embeddings: torch.Size([2, 54, 4096]), image embeddings: torch.Size([2, 2048])
resized image embeddings: torch.Size([2, 54, 2048])
In forward pass. text embeddings: torch.Size([2, 54, 4096]), image embeddings: torch.Size([2, 2048])
resized image embeddings: torch.Size([2, 54, 2048])
Traceback (most recent call last):
  File "/home/jaded79/visual-check/truereader.py", line 414, in <module>
    trainer.train()
  File "/home/jaded79/.conda/envs/mmcoder/lib/python3.11/site-packages/transformers/trainer.py", line 1644, in train
    return inner_training_loop(
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/jaded79/.conda/envs/mmcoder/lib/python3.11/site-packages/transformers/trainer.py", line 1909, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jaded79/visual-check/truereader.py", line 297, in training_step
    gen_latex_code = generate_latex_code(model, input_ids, self.tokenizer, images, max_length=100)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jaded79/visual-check/truereader.py", line 261, in generate_latex_code
    outputs = model(input_ids=gen_tokens, past_key_values=past_key_values, images=images)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jaded79/.conda/envs/mmcoder/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jaded79/.conda/envs/mmcoder/lib/python3.11/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 748, in forward
    output = self._fsdp_wrapped_module(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jaded79/.conda/envs/mmcoder/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jaded79/visual-check/truereader.py", line 201, in forward
    output = super().forward(input_ids=None, attention_mask=attention_mask, past_key_values=past_key_values, inputs_embeds=inputs_embeds, labels=labels, use_cache=use_cache, output_attentions=output_attentions, output_hidden_states=output_hidden_states, return_dict=return_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jaded79/.conda/envs/mmcoder/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 765, in forward
    outputs = self.model(
              ^^^^^^^^^^^
  File "/home/jaded79/.conda/envs/mmcoder/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jaded79/.conda/envs/mmcoder/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 614, in forward
    layer_outputs = decoder_layer(
                    ^^^^^^^^^^^^^^
  File "/home/jaded79/.conda/envs/mmcoder/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jaded79/.conda/envs/mmcoder/lib/python3.11/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 739, in forward
    args, kwargs = _pre_forward(
                   ^^^^^^^^^^^^^
  File "/home/jaded79/.conda/envs/mmcoder/lib/python3.11/site-packages/torch/distributed/fsdp/_runtime_utils.py", line 413, in _pre_forward
    unshard_fn()
  File "/home/jaded79/.conda/envs/mmcoder/lib/python3.11/site-packages/torch/distributed/fsdp/_runtime_utils.py", line 434, in _pre_forward_unshard
    _unshard(state, handles, state._streams["unshard"], state._streams["pre_unshard"])
  File "/home/jaded79/.conda/envs/mmcoder/lib/python3.11/site-packages/torch/distributed/fsdp/_runtime_utils.py", line 329, in _unshard
    handle.unshard()
  File "/home/jaded79/.conda/envs/mmcoder/lib/python3.11/site-packages/torch/distributed/fsdp/flat_param.py", line 918, in unshard
    unsharded_flat_param = self._alloc_padded_unsharded_flat_param()
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jaded79/.conda/envs/mmcoder/lib/python3.11/site-packages/torch/distributed/fsdp/flat_param.py", line 944, in _alloc_padded_unsharded_flat_param
    _alloc_storage(unsharded_flat_param, flat_param._padded_unsharded_size)  # type: ignore[attr-defined]
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jaded79/.conda/envs/mmcoder/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jaded79/.conda/envs/mmcoder/lib/python3.11/site-packages/torch/distributed/fsdp/_utils.py", line 79, in _alloc_storage
    tensor._typed_storage()._resize_(size.numel())
  File "/home/jaded79/.conda/envs/mmcoder/lib/python3.11/site-packages/torch/storage.py", line 764, in _resize_
Traceback (most recent call last):
  File "/home/jaded79/visual-check/truereader.py", line 414, in <module>
    trainer.train()
  File "/home/jaded79/.conda/envs/mmcoder/lib/python3.11/site-packages/transformers/trainer.py", line 1644, in train
    return inner_training_loop(
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/jaded79/.conda/envs/mmcoder/lib/python3.11/site-packages/transformers/trainer.py", line 1909, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jaded79/visual-check/truereader.py", line 297, in training_step
    gen_latex_code = generate_latex_code(model, input_ids, self.tokenizer, images, max_length=100)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jaded79/visual-check/truereader.py", line 261, in generate_latex_code
    outputs = model(input_ids=gen_tokens, past_key_values=past_key_values, images=images)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jaded79/.conda/envs/mmcoder/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jaded79/.conda/envs/mmcoder/lib/python3.11/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 748, in forward
    output = self._fsdp_wrapped_module(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jaded79/.conda/envs/mmcoder/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jaded79/visual-check/truereader.py", line 201, in forward
    output = super().forward(input_ids=None, attention_mask=attention_mask, past_key_values=past_key_values, inputs_embeds=inputs_embeds, labels=labels, use_cache=use_cache, output_attentions=output_attentions, output_hidden_states=output_hidden_states, return_dict=return_dict)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jaded79/.conda/envs/mmcoder/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 765, in forward
    outputs = self.model(
              ^^^^^^^^^^^
  File "/home/jaded79/.conda/envs/mmcoder/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jaded79/.conda/envs/mmcoder/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py", line 614, in forward
    layer_outputs = decoder_layer(
                    ^^^^^^^^^^^^^^
  File "/home/jaded79/.conda/envs/mmcoder/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jaded79/.conda/envs/mmcoder/lib/python3.11/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 739, in forward
    args, kwargs = _pre_forward(
                   ^^^^^^^^^^^^^
  File "/home/jaded79/.conda/envs/mmcoder/lib/python3.11/site-packages/torch/distributed/fsdp/_runtime_utils.py", line 413, in _pre_forward
    unshard_fn()
  File "/home/jaded79/.conda/envs/mmcoder/lib/python3.11/site-packages/torch/distributed/fsdp/_runtime_utils.py", line 434, in _pre_forward_unshard
    _unshard(state, handles, state._streams["unshard"], state._streams["pre_unshard"])
  File "/home/jaded79/.conda/envs/mmcoder/lib/python3.11/site-packages/torch/distributed/fsdp/_runtime_utils.py", line 329, in _unshard
    handle.unshard()
  File "/home/jaded79/.conda/envs/mmcoder/lib/python3.11/site-packages/torch/distributed/fsdp/flat_param.py", line 918, in unshard
    unsharded_flat_param = self._alloc_padded_unsharded_flat_param()
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jaded79/.conda/envs/mmcoder/lib/python3.11/site-packages/torch/distributed/fsdp/flat_param.py", line 944, in _alloc_padded_unsharded_flat_param
    _alloc_storage(unsharded_flat_param, flat_param._padded_unsharded_size)  # type: ignore[attr-defined]
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jaded79/.conda/envs/mmcoder/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/jaded79/.conda/envs/mmcoder/lib/python3.11/site-packages/torch/distributed/fsdp/_utils.py", line 79, in _alloc_storage
    tensor._typed_storage()._resize_(size.numel())
  File "/home/jaded79/.conda/envs/mmcoder/lib/python3.11/site-packages/torch/storage.py", line 764, in _resize_
    self._untyped_storage.resize_(size * self._element_size())
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 388.00 MiB (GPU 0; 79.35 GiB total capacity; 75.41 GiB already allocated; 353.19 MiB free; 77.17 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
wandb: Waiting for W&B process to finish... (failed 1).
    self._untyped_storage.resize_(size * self._element_size())
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 388.00 MiB (GPU 1; 79.35 GiB total capacity; 75.41 GiB already allocated; 355.19 MiB free; 77.17 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /home/jaded79/visual-check/wandb/offline-run-20230327_091506-gf5r5bpl
wandb: Find logs at: ./wandb/offline-run-20230327_091506-gf5r5bpl/logs
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 92898 closing signal SIGTERM
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 1 (pid: 92899) of binary: /home/jaded79/.conda/envs/mmcoder/bin/python
Traceback (most recent call last):
  File "/home/jaded79/.conda/envs/mmcoder/bin/torchrun", line 8, in <module>
    sys.exit(main())
             ^^^^^^
  File "/home/jaded79/.conda/envs/mmcoder/lib/python3.11/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 346, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/jaded79/.conda/envs/mmcoder/lib/python3.11/site-packages/torch/distributed/run.py", line 794, in main
    run(args)
  File "/home/jaded79/.conda/envs/mmcoder/lib/python3.11/site-packages/torch/distributed/run.py", line 785, in run
    elastic_launch(
  File "/home/jaded79/.conda/envs/mmcoder/lib/python3.11/site-packages/torch/distributed/launcher/api.py", line 134, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jaded79/.conda/envs/mmcoder/lib/python3.11/site-packages/torch/distributed/launcher/api.py", line 250, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
truereader.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2023-03-27_09:15:39
  host      : cs-1-2.rc.byu.edu
  rank      : 1 (local_rank: 1)
  exitcode  : 1 (pid: 92899)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
